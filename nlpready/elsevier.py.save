import os
import time
from io import BytesIO
from os.path import join
from typing import TYPE_CHECKING, Iterator

import click
import requests
from bs4 import BeautifulSoup
from lxml import etree

from .mlabc import Clean, Config, Generate, read_suba_papers_csv, readxml


if TYPE_CHECKING:
    from bs4 import BeautifulSoup, Tag
    from lxml.etree import _Element as Element


ISSN = {"elsevier": "elsevier"}

PMID_ELSEVIER = "http://api.elsevier.com/content/article/pubmed_id/{}"
EKEY = "305ac4275ea475891668f6a71234efbc"
Headers = {"X-ELS-APIKey": EKEY}


def elsevier(pmid:str, url:str=PMID_ELSEVIER) -> str | None:
    """Given a PUBMED id return the Elsevier XML as text."""
    resp = requests.get(
        url.format(pmid), headers=Headers, params={"view": "full"}  # Do we need this?
    )

    # for row in Events().parse(BytesIO(resp.content),'elsevier'):
    #    print(row)#,end=' ')

    soup = BeautifulSoup(BytesIO(resp.content), "lxml")
    if soup.find("service-error"):
        # print('no such document:', pmid, resp.text, file=sys.stderr)
        return None
    # seems like elsevier gives back incorrect articles see e.g. 24381066 argh!
    p = soup.find("pubmed-id")
    if p:
        pstr = p.text.strip()
        assert pstr == pmid, (pstr, pmid)
    else:
        assert p, ("no pubmed-id", pmid)

    return resp.text
    # return soup.prettify()


def ensure_dir(d:str) -> None:
    t = join(Config.DATADIR, d)
    if not os.path.isdir(t):
        os.makedirs(t, exist_ok=True)


def download_elsevier(issn:str="elsevier", sleep:float=0.5, mx:int=0) -> None:
    """Download any Elsevier XML files using pubmed IDs."""
    failed = set(readxml("failed_elsevier"))
    done = set(
        readxml("xml_elsevier")
    )  # | set(readxml('xml_epmc'))  # TODO: don't duplicate EPMC

    todo = [p.pmid for p in read_suba_papers_csv() if p.pmid not in failed | done]

    todox = todo.copy()
    print("done: %d failed: %d todo: %d" % (len(done), len(failed), len(todox)))
    if mx:
        todo = todo[:mx]
    if not todo:
        return
    for pmid in todo:
        try:
            xml = elsevier(pmid)
            if xml is None:
                d = "failed_elsevier"
                xml = "failed"
                failed.add(pmid)
            else:
                d = "xml_elsevier"
                done.add(pmid)
        except AssertionError as e:
            print("failed pubmed test", pmid, e)
            d = "failed_elsevier"
            xml = "incorrect_pmid"
            failed.add(pmid)

        ensure_dir(d)
        with open(join(Config.DATADIR, d, f"{pmid}.xml"), "w") as fp:
            fp.write(xml)
        todox.remove(pmid)
        print(
            "done: %d failed: %d todo: %d -- %s"
            % (len(done), len(failed), len(todox), pmid)
        )
        time.sleep(sleep)


def getxmlelsevier(pmid:str) -> Element:
    parser = etree.XMLParser(ns_clean=True)
    with open(join(Config.DATADIR, "xml_elsevier", f"{pmid}.xml"), "rb") as fp:
        tree = etree.parse(fp, parser)

    root = tree.getroot()
    return root


E = "/e:full-text-retrieval-response"
ART = "*[self::ja:converted-article or self::ja:article]"

CE = "http://www.elsevier.com/xml/common/dtd"
TAG = "{%s}%%s" % CE
XREFS = {TAG % "cross-ref", TAG % "cross-refs"}
ITALIC = {TAG % "italic"}


def para2txt2(e: Element) -> Iterator[str]:
    t: Element
    for t in e.xpath(".//text()"):
        p = t.getparent()
        if p.tag in XREFS:
            if p.tail == t:
                yield p.tail
            else:
                yield "CITATION"  # '[%s]' % p.attrib['refid']
        elif p.tag in ITALIC and p.tail != t:
            # yield '<i>%s</i>' % t
            yield str(t)
        else:
            yield str(t)


class Elsevier:
    def __init__(self, root:Element) -> None:
        self.root = root
        ns = root.nsmap.copy()
        ns["e"] = ns.pop(None)
        self.ns : dict[str,str] = ns # type: ignore
        self.figures = {
            f.attrib["id"]: f
            for f in self.root.xpath(
                E + "/e:originalText/xocs:doc/xocs:serial-item//ce:figure[@id]",
                namespaces=ns,
            )
        }


        self.tables = {
            f.attrib["id"]: f
            for f in self.root.xpath(
                E + "/e:originalText/xocs:doc/xocs:serial-item//ce:table[@id]",
                namespaces=ns,
            )
        }

    @property
    def pubmed(self) -> str:
        r = self.root.xpath(E + "/e:pubmed-id", namespaces=self.ns)
        if not r:
            return None
        return r[0].text.strip()

    def title(self) -> str | None:
        r = self.root.xpath(E + "/e:coredata/dc:title", namespaces=self.ns)
        if not r:
            return None
        return r[0].text.strip()

    def results(self) -> list[Element]:

        secs = self.root.xpath(
            E
            + "/e:originalText/xocs:doc/xocs:serial-item/"
            + ART
            + "/ja:body/ce:sections",
            namespaces=self.ns,
        )
        for sec in secs:
            for s in sec.xpath("./ce:section", namespaces=self.ns):
                for t in s.xpath(".//ce:section-title/text()", namespaces=self.ns):
                    if t.lower().find("results") >= 0:
                        return [s]

        return []

    def methods(self) -> list[Element]:

        secs = self.root.xpath(
            E
            + "/e:originalText/xocs:doc/xocs:serial-item/"
            + ART
            + "/ja:body/ce:sections",
            namespaces=self.ns,
        )
        sec: Element
        for sec in secs:
            for s in sec.xpath("./ce:section", namespaces=self.ns):
                for t in s.xpath(".//ce:section-title/text()", namespaces=self.ns):
                    txt = t.lower()
                    if txt.find("methods") >= 0:
                        return s
                    if txt.find("experimental procedures") >= 0:
                        return [s]

        return []

    def abstract(self) -> str | None:

        secs = self.root.xpath(
            E
            + "/e:originalText/xocs:doc/xocs:serial-item/"
            + ART
            + "/ja:head/ce:abstract/ce:abstract-sec",
            namespaces=self.ns,
        )
        if not secs:
            return None
        return secs[0]

    def tostr(self, seclist: list[Element]) -> list[str]:
        def txt(p):
            res = []
            for t in para2txt2(p):
                res.append(t)

            txt = "".join(res)
            txt = self.SPACE.sub(" ", txt)
            return txt.strip()
        def run():
            for sec in seclist:
                for p in sec.xpath(
                    ".//*[self::ce:para or self::ce:simple-para]", namespaces=self.ns
                ):
                    # TODO: <ce:float-anchor refid='FIG2'/>
                    yield txt(p)
                    for f in p.xpath(".//ce:float-anchor[@refid]", namespaces=self.ns):
                        fid = f.attrib["refid"]
                        if fid in self.figures:
                            fig = self.figures[fid]
                            t = " ".join(
                                txt(c) for c in fig.xpath(".//ce:caption", namespaces=self.ns)
                            )
                            yield self.FIGURE % t
                        else:
                            fig = self.tables[fid]
                            t = " ".join(
                                txt(c) for c in fig.xpath(".//ce:caption", namespaces=self.ns)
                            )
                            yield self.TABLE % t
        return list(run())

class GenerateElsevier(Generate):
    def create_clean(self, soup:BeautifulSoup, pmid:str) -> Elsevier:
        ret = Elsevier(soup)
        # print('HERE', ret.pubmed, pmid)
        if ret.pubmed != pmid:
            click.secho(f"pubmed incorrect {ret.pubmed} expecting: {pmid}", fg="red")
        assert ret.pubmed == pmid, (ret.pubmed, pmid)
        return ret

    def get_soup(self, gdir: str, pmid: str) -> BeautifulSoup:
        return getxmlelsevier(pmid)


def gen_elsevier(issn: str = "elsevier") -> None:
    o = GenerateElsevier(issn)
    o.run()


def gen_elsevier_old(issn:str="elsevier") -> None:
    """Convert Elsevier XML files into "cleaned" text files."""
    td = join(Config.DATADIR, "cleaned_elsevier")
    if not os.path.isdir(td):
        os.mkdir(td)

    for pmid in readxml("xml_elsevier"):

        root = getxmlelsevier(pmid)
        e = Elsevier(root)

        a = e.abstract()
        m = e.methods()
        r = e.results()
        if a is None or m is None or r is None:
            click.secho(
                "{}: missing: abs {}, methods {}, results {}".format(
                    pmid, a is None, m is None, r is None
                ),
                fg="red",
            )
            continue
        fname = join(Config.DATADIR, "cleaned_elsevier", f"{pmid}_cleaned.txt")
        if os.path.exists(fname):
            click.secho("overwriting %s" % fname, fg="yellow")

        with open(fname, "w", encoding="utf-8") as fp:
            w = " ".join(e.tostr(a))
            print("!~ABS~! %s" % w, file=fp)
            w = " ".join(e.tostr(r))
            print("!~RES~! %s" % w, file=fp)
            w = " ".join(e.tostr(m))
            print("!~MM~! %s" % w, file=fp)


def check_elsevier(remove:bool=False) -> None:
    for pmid in readxml("xml_elsevier"):
        root = getxmlelsevier(pmid)
        e = Elsevier(root)
        if pmid != e.pubmed:
            print("incorrect pubmed!", pmid, e.pubmed)
            if remove:
                os.remove(join(Config.DATADIR, "xml_elsevier", "{pmid}.xml"))


if __name__ == "__main__":
    check_elsevier(remove=True)
    download_elsevier(sleep=5.0)
    # gen_elsevier()
